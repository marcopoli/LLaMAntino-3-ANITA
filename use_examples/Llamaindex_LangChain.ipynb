{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5b6288e-a1f9-478b-98a8-3da68e93b6a7",
      "metadata": {
        "id": "a5b6288e-a1f9-478b-98a8-3da68e93b6a7"
      },
      "source": [
        "# Understanding LlamaIndex\n",
        "\n",
        "Initially known as GPT Index, LlamaIndex has evolved into an indispensable ally for developers. It's like a multi-tool that helps in various stages of working with data and large language models -\n",
        "\n",
        "\n",
        "1. Firstly, it helps in **'ingesting'** data, which means getting the data from its original source into the system.\n",
        "2. Secondly, it helps in **'structuring'** that data, which means organizing it in a way that the language models can easily understand.\n",
        "3. Thirdly, it aids in **'retrieval'**, which means finding and fetching the right pieces of data when needed.\n",
        "4. Lastly, it simplifies **'integration'**, making it easier to meld your data with various application frameworks.\n",
        "\n",
        "\n",
        "\n",
        "When we dive a little deeper into the mechanics of LlamaIndex, we find three main heroes doing the heavy lifting.\n",
        "\n",
        "\n",
        "*   The *'data connectors'* are the diligent gatherers, fetching your data from wherever it resides, be it APIs, PDFs, databases, or external apps like Gmail, Notion, Airtable.\n",
        "*   The *'data indexes'* are the organized librarians, arranging your data neatly so that it's easily accessible.\n",
        "*   And the *'engines'* are the translators (LLMs), making it possible to interact with your data using natural language and ultimately create applications and workflows.\n",
        "\n",
        "Credits: https://nanonets.com/blog/llamaindex/#understanding-llamaindex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's configure LLaMA-Index\n",
        "<img src=\"https://www.llamaindex.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FhomepageHeroProcess.f9904fd2.png&w=1920&q=75\" width=500px>"
      ],
      "metadata": {
        "id": "n_caQs6mCbNO"
      },
      "id": "n_caQs6mCbNO"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index ipywidgets"
      ],
      "metadata": {
        "id": "OdixM4k1DuFL"
      },
      "id": "OdixM4k1DuFL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "0Wp255wFJD8N"
      },
      "id": "0Wp255wFJD8N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before exploring the exciting features, let's first install LlamaIndex on your system. If you're familiar with Python, this will be easy. Use this command to install:"
      ],
      "metadata": {
        "id": "Dji5pFFeJudD"
      },
      "id": "Dji5pFFeJudD"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "P4xYzBUgCMcD"
      },
      "id": "P4xYzBUgCMcD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5zGEdBxsujM",
        "outputId": "ee9b54d8-e114-447a-da8c-9f9efc95bb62"
      },
      "id": "S5zGEdBxsujM",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download our Documents!"
      ],
      "metadata": {
        "id": "4HENF0YqJhLB"
      },
      "id": "4HENF0YqJhLB"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/karan-nanonets/llamaindex-guide/raw/main/bcg-2022-annual-sustainability-report-apr-2023.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MG-lSfFBmM5",
        "outputId": "1ba2d078-e63b-46ad-c9f4-989c8a828d58"
      },
      "id": "5MG-lSfFBmM5",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-30 11:12:36--  https://github.com/karan-nanonets/llamaindex-guide/raw/main/bcg-2022-annual-sustainability-report-apr-2023.pdf\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/karan-nanonets/llamaindex-guide/main/bcg-2022-annual-sustainability-report-apr-2023.pdf [following]\n",
            "--2024-04-30 11:12:37--  https://raw.githubusercontent.com/karan-nanonets/llamaindex-guide/main/bcg-2022-annual-sustainability-report-apr-2023.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19069924 (18M) [application/octet-stream]\n",
            "Saving to: ‘bcg-2022-annual-sustainability-report-apr-2023.pdf’\n",
            "\n",
            "bcg-2022-annual-sus 100%[===================>]  18.19M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-04-30 11:13:02 (208 MB/s) - ‘bcg-2022-annual-sustainability-report-apr-2023.pdf’ saved [19069924/19069924]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Llamaindex Documents\n",
        "Data connectors, also referred to as Readers, are essential components in LlamaIndex that facilitate the ingestion of data from various sources and formats, converting them into a simplified Document representation consisting of text and basic metadata.\n",
        "\n",
        "LlamaHub is an open-source repository hosting data connectors which can be seamlessly integrated into any LlamaIndex application. All the connectors present here can be used as follows -"
      ],
      "metadata": {
        "id": "yRwTql6NJ2XX"
      },
      "id": "yRwTql6NJ2XX"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "71e7b813-53b8-4eca-91ac-262573c53531",
      "metadata": {
        "id": "71e7b813-53b8-4eca-91ac-262573c53531"
      },
      "outputs": [],
      "source": [
        "#Just load a PDF Example about a Sustainability Report of 2023\n",
        "#Note  that it contains many sections, tables, and images\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(\n",
        "    input_files=[\"bcg-2022-annual-sustainability-report-apr-2023.pdf\"]\n",
        ")\n",
        "\n",
        "pdf_documents = reader.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given example below loads the wikipedia pages about a few countries from around the globe. Basically, the the top page that appears in the search results with each element of the list as a search query is ingested."
      ],
      "metadata": {
        "id": "p871Rz6RKdqq"
      },
      "id": "p871Rz6RKdqq"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92f21476-5b85-4dff-aa9f-fe01148ce0a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92f21476-5b85-4dff-aa9f-fe01148ce0a7",
        "outputId": "4a874777-892f-4225-b0c4-7184b01e8ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-578c05cda755>:4: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
            "  WikipediaReader = download_loader(\"WikipediaReader\")\n"
          ]
        }
      ],
      "source": [
        "#Let's enrich our collection downloading also some documents from Wikipedia\n",
        "!pip install wikipedia\n",
        "from llama_index.core import download_loader\n",
        "WikipediaReader = download_loader(\"WikipediaReader\")\n",
        "loader = WikipediaReader()\n",
        "wikipedia_documents = loader.load_data(pages=['Iceland Country', 'Kenya Country', 'Germany Country'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variety of data connectors here is pretty exhaustive, some of which include:\n",
        "\n",
        "*  **SimpleDirectoryReader**: Supports a broad range of file types (.pdf, .jpg, .png, .docx, etc.) from a local file directory.\n",
        "*  NotionPageReader: Ingests data from Notion.\n",
        "*  SlackReader: Imports data from Slack.\n",
        "*  AirtableReader: Imports data from Airtable.\n",
        "*  ApifyActor: Capable of web crawling, scraping, text extraction, and file downloading.\n",
        "\n",
        "<img src=\"https://nanonets.com/blog/content/images/size/w1600/2023/10/image-14.png\" width=500px>"
      ],
      "metadata": {
        "id": "Nnc9y9QyKCW9"
      },
      "id": "Nnc9y9QyKCW9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating LlamaIndex Nodes\n",
        "In LlamaIndex, once the data has been ingested and represented as Documents, there's an option to further process these Documents into Nodes. Nodes are more granular data entities that represent \"chunks\" of source Documents, which could be text chunks, images, or other types of data. They also carry metadata and relationship information with other nodes, which can be instrumental in building a more structured and relational index.\n",
        "\n",
        "**Basic**\n",
        "To parse Documents into Nodes, LlamaIndex provides NodeParser classes. These classes help in automatically transforming the content of Documents into Nodes, adhering to a specific structure that can be utilized further in index construction and querying.\n",
        "\n",
        "Here's how you can use a SimpleNodeParser to parse your Documents into Nodes:"
      ],
      "metadata": {
        "id": "9a-oMeW-Kkg5"
      },
      "id": "9a-oMeW-Kkg5"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "31bc53c3-a63d-48bb-ac65-0ce2430498ab",
      "metadata": {
        "id": "31bc53c3-a63d-48bb-ac65-0ce2430498ab"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "\n",
        "parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=20)\n",
        "\n",
        "pdf_nodes = parser.get_nodes_from_documents(pdf_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this snippet, SimpleNodeParser.from_defaults() initializes a parser with default settings, and get_nodes_from_documents(documents) is used to parse the loaded Documents into Nodes."
      ],
      "metadata": {
        "id": "i5MvPAFAKu2Z"
      },
      "id": "i5MvPAFAKu2Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating LlamaIndex Index\n",
        "The core essence of LlamaIndex lies in its ability to build structured indices over ingested data, represented as either Documents or Nodes. This indexing facilitates efficient querying over the data. Let's delve into how to build indices with both Document and Node objects, and what happens under the hood during this process. By default the library uses OpenAI ChatGPT as engine.\n",
        "\n",
        "In the following piece of code we set **LLaMA-3**."
      ],
      "metadata": {
        "id": "1ZIW5C8yK2AL"
      },
      "id": "1ZIW5C8yK2AL"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "# Model names (make sure you have access on HF)\n",
        "LLAMA3_7B = \"m-polignano-uniba/LLaMAntino-3-ANITA_test\"\n",
        "selected_model = LLAMA3_7B\n",
        "\n",
        "query_wrapper_prompt = PromptTemplate(\n",
        "    \"{query_str}\"\n",
        ")\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=2048,\n",
        "    max_new_tokens=1024,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=selected_model,\n",
        "    model_name=selected_model,\n",
        "    device_map=\"cuda:0\",\n",
        "    # change these settings below depending on your GPU\n",
        "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_4bit\": True},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "65f4ebb79b3d419a927211270de9eb4f",
            "16679fbcbb494eeba9686b7df33de787",
            "f07e65c51875408ab749b0240a0de859",
            "99c488ab0b1e459db06db81f4aec095e",
            "4bf7612561d54518ad42cf96b6284523",
            "2a11c9cca9f14874b51e540149b671a4",
            "1652f43eda1146d6a7064236866489d7",
            "ccc4386172724a4d83bbde48e3b1244d",
            "9a067fff60644a9b8102393b56a749bd",
            "18868c50f40941d398398fb604958410",
            "99688678186b4d8fb8c20ec406b5cbdc"
          ]
        },
        "id": "JG9WQUtLFCqv",
        "outputId": "1cc079af-e0e8-46aa-e0c7-8f227ba4d6ee"
      },
      "id": "JG9WQUtLFCqv",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65f4ebb79b3d419a927211270de9eb4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v1\")\n",
        "\n",
        "from llama_index.core import Settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "Yv2f4j23u3pa"
      },
      "id": "Yv2f4j23u3pa",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6a670aad-0e0b-440a-93ea-cb1959621526",
      "metadata": {
        "id": "6a670aad-0e0b-440a-93ea-cb1959621526"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "index = VectorStoreIndex(pdf_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different types of indices in LlamaIndex handle data in distinct ways:\n",
        "\n",
        "*  Vector Store Index: Stores each Node and a corresponding embedding in a Vector Store, and queries involve fetching the top-k most similar Nodes.\n",
        "*  Tree Index: Builds a hierarchical tree from a set of Nodes, and queries involve traversing from root nodes down to leaf nodes.\n",
        "*  Keyword Table Index: Extracts keywords from each Node to build a mapping, and queries extract relevant keywords to fetch corresponding Nodes.\n",
        "\n",
        "**Under the Hood:**\n",
        "\n",
        "The Documents are parsed into Node objects, which are lightweight abstractions over text strings that additionally keep track of metadata and relationships.\n",
        "Index-specific computations are performed to add Node into the index data structure.\n",
        "\n",
        "For a vector store index, an embedding model is called (either via API or locally) to compute embeddings for the Node objects. For a document summary index, an LLM (Language Model) is called to generate a summary."
      ],
      "metadata": {
        "id": "ahZsRNRDLRBD"
      },
      "id": "ahZsRNRDLRBD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now create a summary index for the **Wikipedia nodes**. We find the relevant index from the list of supported indices, and settle on the Document Summary Index."
      ],
      "metadata": {
        "id": "eRCCUSrVL3qn"
      },
      "id": "eRCCUSrVL3qn"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "182fa3c7-5e64-46ca-8cd6-28d11abbe84c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "2a10ec65cf124e5786363d89bd674722",
            "1249c60942384ec3bc327c2b4ede87fd",
            "9cd4f0061c1b47938f6c1fbdb98fa5eb",
            "aecb765d0faa487c847e0dcc1e782d28",
            "d1b264d288d24dca974acd605fa7fbb3",
            "f620ceb99dae48eebfb7967121357677",
            "02f3f3d288d44b86b7e13982ebb461ea",
            "862c15fb971f4dd4945cd9f2bbdd3690",
            "17fee8fd88de4acb964b5034c98af60b",
            "ac14167c36fe4c49b637a6b27f9de6a1",
            "64f7530c665e405096b7704ab5865337",
            "7e2b45dc54a24791baacc4ca65b3e12d",
            "ed5d67f51f044555acef524d052fdded",
            "4d9a479bb54546dbbf2a709c38452281",
            "e3e4eb0f40494de991771a3689dc5f24",
            "f7ad0564df114960b547e1c8386f6718",
            "b1a5e409fc204eeca9078849c2983257",
            "09ad2cba5c8642beacc33ab69c535bea",
            "3003770c9d6e4a19b844823767fc726b",
            "71ed12553a0c4f72b9c63580a1613b89",
            "d4f6d11a0e9941b79a78cccc3e6a07a7",
            "c3de9fd905d445039dc25eb617ae031f",
            "45a1137289434f73807b434d7dcf8e5f",
            "547938867d514408996c62d692d3e1f3",
            "ebe6393c2ea1477b938da97e40e0fad0",
            "384d51444d10469c9bb8f19c3d58b538",
            "99f0ad1ee34f487c86ad166aa691bbed",
            "446f7cb794c34e6d8aa98eb84b75a701",
            "dd223c323a5a43ae98c91492a851b3c9",
            "008055b28f914fad8e4ede74589c8321",
            "1cc26789bf8d4870900a355f88f4d123",
            "b7147407452f4a7ea0ace1e87e1a51c6",
            "813f3352eb404a68884e68dde724de5b"
          ]
        },
        "id": "182fa3c7-5e64-46ca-8cd6-28d11abbe84c",
        "outputId": "7e110371-e830-408e-d501-9e1f5433179a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a10ec65cf124e5786363d89bd674722"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Summarizing documents:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e2b45dc54a24791baacc4ca65b3e12d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current doc id: 14531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:500: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current doc id: 188171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:500: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current doc id: 11867\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45a1137289434f73807b434d7dcf8e5f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.core.indices.document_summary import DocumentSummaryIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import get_response_synthesizer\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=512)\n",
        "\n",
        "# default mode of building the index\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "    response_mode=\"simple_summarize\", use_async=False\n",
        ")\n",
        "\n",
        "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
        "    wikipedia_documents,\n",
        "    llm=llm,\n",
        "    transformations=[splitter],\n",
        "    response_synthesizer=response_synthesizer,\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Storing an Index\n",
        "LlamaIndex's storage capability is built for adaptability, especially when dealing with evolving data sources. This section outlines the functionalities provided for managing data storage, including customization and persistence features.\n",
        "\n",
        "**Persistence (Basic)**\n",
        "There might be instances where you might want to save the index for future use, and LlamaIndex makes this straightforward. With the persist() method, you can store data, and with the load_index_from_storage() method, you can retrieve data effortlessly.\n",
        "\n"
      ],
      "metadata": {
        "id": "3VM0xGKPMK87"
      },
      "id": "3VM0xGKPMK87"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fa91c67c-1f4e-4c98-be35-5760815f6d12",
      "metadata": {
        "id": "fa91c67c-1f4e-4c98-be35-5760815f6d12"
      },
      "outputs": [],
      "source": [
        "index.storage_context.persist(persist_dir=\"BCG Report\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Index to Query Data\n",
        "After having established a well-structured index using LlamaIndex, the next pivotal step is querying this index to extract meaningful insights or answers to specific inquiries. This segment elucidates the process and methods available for querying the data indexed in LlamaIndex."
      ],
      "metadata": {
        "id": "TUyHFdLvNX7A"
      },
      "id": "TUyHFdLvNX7A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**High-Level Query API**\n",
        "\n",
        "LlamaIndex provides a high-level API that facilitates straightforward querying, ideal for common use cases."
      ],
      "metadata": {
        "id": "9qzjYRFXNi7I"
      },
      "id": "9qzjYRFXNi7I"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8de52362-2389-45ac-b641-f8f4bd661523",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8de52362-2389-45ac-b641-f8f4bd661523",
        "outputId": "0ffdfdb8-d65e-4261-c7aa-a71f9d328534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Morocco is mentioned in the context of a countrywide project with ramifications affecting the lives of millions of people, including expanding universal health care coverage, restructuring the reform agenda, and supporting social reforms. \n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# configure retriever\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=2,\n",
        ")\n",
        "# configure response synthesizer\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "    response_mode=\"simple_summarize\",\n",
        ")\n",
        "# assemble query engine\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        ")\n",
        "\n",
        "query = 'In what context is Morocco mentioned in the report?'\n",
        "\n",
        "response = query_engine.query(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9747fa0d-d02b-49ba-9663-ed450ff914e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9747fa0d-d02b-49ba-9663-ed450ff914e1",
        "outputId": "a8d44c17-934d-4aaf-bab9-b8c7c274c0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Pfizer announced “An Accord for a Healthier World” to provide access to innovative medicines for people living in 45 lower-income countries. 2. Pfizer sought BCG’s assistance in developing a partnership model that mitigates risks, meets regulatory requirements, and ensures high distribution security. 3. BCG worked on distribution, enabled sustainable prices, and conducted a regulatory analysis to initiate drug approval processes on time while also leveraging existing registrations as much as possible. 4. Pfizer also engages in a broader effort to ensure the effective distribution of the provided medicines. 5. Pfizer announced plans to further expand its Accord for a Healthier World to nextend access to the full portfolio of medicines and vaccines to all eligible individuals. 6. BCG’s Internal Sustainability Strategic Committee oversees the development, implementation, and progress of the firm’s sustainability strategy and net-zero target, including oversight of climate-related risks with support from the Audit and Risk Committee. 7. The Strat Co., which currently consists of BCG’s global chair, chief sustainability officer, chief financial officer, and people chair, meets monthly. 8. The Internal Sustainability Team, led by BCG’s chief sustainability officer, David Webb, is responsible for the day-to-day operation of the sustainability program. 9. BCG has a thorough process in place to monitor climate-related risks and our mitigation approach. 10. BCG has not identified any risks that could have a substantial impact on the firm’s sustainability program. 11. BCG’s Task Force on Climate-Related Financial Disclosures (TCFD) Index is a global company facing various physical and transitional climate-related risks. 12. BCG’s Internal Sustainability Strategic Committee (Strat Co.) oversees the development, implementation, and progress of the firm’s sustainability strategy and net-zero target, including oversight of climate-related risks with support from the Audit and Risk Committee. 13. The Strat Co., which currently consists of BCG’s global chair, chief sustainability officer, chief financial officer, and people chair, meets monthly. 14. The Internal Sustainability Team, led by BCG’s chief sustainability officer, David Webb, is responsible for the day-to-day operation of the sustainability program. 15. BCG has a thorough process in place to monitor climate-related risks and our mitigation approach. 16. BCG has not identified any risks that could have a substantial impact on the firm’s sustainability program. 17. BCG’s Task Force on Climate-Related Financial Disclosures (TCFD) Index is a global company facing various physical and transitional climate-related risks. 18. BCG’s Internal Sustainability Strategic Committee (Strat Co.) oversees the development, implementation, and progress of the firm’s sustainability strategy and net-zero target, including oversight of climate-related risks with support from the Audit and Risk Committee. 19. The Strat Co., which currently consists of BCG’s global chair, chief sustainability officer, chief financial officer, and people chair, meets monthly. 20. The Internal Sustainability Team, led by BCG’s chief sustainability officer, David Webb, is responsible for the day-to-day operation of the sustainability program. 21. BCG has a thorough process in place to monitor climate-related risks and our mitigation approach. 22. BCG has not identified any risks that could have a substantial impact on the firm’s sustainability program. 23. BCG’s Task Force on Climate-Related Financial Disclosures (TCFD) Index is a global company facing various physical and transitional climate-related risks. 24. BCG’s Internal Sustainability Strategic Committee (Strat Co.) oversees the development, implementation, and progress of the firm’s sustainability strategy and net-zero target, including oversight of climate-related risks with support from the Audit and Risk Committee. 25. The Strat Co., which currently consists of BCG’s global chair, chief sustainability officer, chief financial officer, and people chair, meets monthly. 26. The Internal Sustainability Team, led by BCG’s chief sustainability officer, David Webb, is responsible for the day-to-day operation of the sustainability program. 27. BCG has a thorough process in place to monitor climate-related risks and our mitigation approach. 28. BCG has not identified any risks that could have a substantial impact on the firm’s sustainability program. 29. BCG’s Task Force on Climate-Related Financial Disclosures (TCFD) Index is a global company facing various physical and transitional climate-related risks. 30. BCG’s Internal Sustainability Strategic Committee (Strat Co.) oversees the development, implementation, and progress of the firm’s sustainability strategy and net-zero target, including oversight of climate-related risks with support from the Audit and Risk Committee. 31. The Strat Co., which currently consists of BCG’s global chair, chief sustainability officer, chief financial officer, and people chair, meets monthly. 32. The Internal Sustainability Team, led by BCG’s chief sustainability officer, David Webb, is responsible for the day-to-day operation of the sustainability program. 33. BCG\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query('List measures taken to address diseases occuring in developing industries')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain!\n",
        "A common use case for developing AI chat bots is ingesting PDF documents and allowing users to ask questions, inspect the documents, and learn from them. In this tutorial we will start with a 100% blank project and build an end to end chat application that allows users to chat about the Sustainability report PDF.\n",
        "\n",
        "The **Langchain** streamlines the process of achieving these objectives, guiding users through each stage systematically. With support for multiple services, including embedding models, chat models, and vector databases, Langchain facilitates the creation of chatbots tailored for PDF interactions. This seamless workflow extends to integrating with Streamlit, handling multiple PDFs, and utilizing RAG for semantic search capabilities."
      ],
      "metadata": {
        "id": "SjPitAN9NejP"
      },
      "id": "SjPitAN9NejP"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.20.3\n",
        "#!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n",
        "!pip install -q datasets loralib sentencepiece\n",
        "#!pip -q install bitsandbytes accelerate xformers\n",
        "!pip -q install langchain\n",
        "!pip -q install peft chromadb\n",
        "!pip -q install unstructured\n",
        "!pip install -q sentence_transformers\n",
        "!pip -q install pypdf"
      ],
      "metadata": {
        "id": "Kr9pYtD6NrVh"
      },
      "id": "Kr9pYtD6NrVh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "gckExHRvO1sP"
      },
      "id": "gckExHRvO1sP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kpXQGhHlij6q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
      ],
      "id": "kpXQGhHlij6q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Langchain?\n",
        "Langchain is an open-source tool, ideal for enhancing chat models like GPT-4 or LLaMA-2. It connects external data seamlessly, making models more agentic and data-aware. With Langchain, you can introduce fresh data to models like never before. The platform offers multiple chains, simplifying interactions with language models. In addition to Langchain, tools like Models for creating vector embeddings play a crucial role. When dealing with Langchain, the capability to render images of a PDF file is also noteworthy. Now, let’s delve into the significance of text embeddings."
      ],
      "metadata": {
        "id": "g32uRYBy0sKV"
      },
      "id": "g32uRYBy0sKV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's start loading the LLM model with quantization\n",
        "We will use the LLaMA-2 chat model in order to allow a natural interaction between the user and the system."
      ],
      "metadata": {
        "id": "DmtXWTKwOiHs"
      },
      "id": "DmtXWTKwOiHs"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YGSWYfyd2A0L"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False)"
      ],
      "id": "YGSWYfyd2A0L"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "43408164871c4a5eba75592f460136fd",
            "d3f45637f3154033aeb04a9f259420ae",
            "f46125540b5d4820a5632ca269781e67",
            "8f9b4afb5c6e4d87b737e3fc27f58a27",
            "e74456dc69b4451e9d57b488300ff4e9",
            "f1cbc57ba1a64a41843bde2e72bfb756",
            "c59561dd012c41a992f960234cb27a2c",
            "58dc2931de724ac893a074587e8825ef",
            "88c921d7855f43e081c4fe3bf738aed8",
            "7ea5809788bd4ea89041fc192bdac061",
            "772c7b17aea7402db5f5670b43d26a42"
          ]
        },
        "id": "bV3JsId72B3g",
        "outputId": "e03d966d-9b76-4b63-a752-431698db6120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43408164871c4a5eba75592f460136fd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/LLaMAntino-3-ANITA_test\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"m-polignano-uniba/LLaMAntino-3-ANITA_test\", quantization_config = bnb_config,device_map={\"\":0})"
      ],
      "id": "bV3JsId72B3g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Embeddings**\n",
        "Text embeddings are the heart and soul of Large Language Operations. Technically, we can work with language models with natural language but storing and retrieving natural language is highly inefficient. For example, in this project, we will need to perform high-speed search operations over large chunks of data. It is impossible to perform such operations on natural language data.\n",
        "\n",
        "To make it more efficient, we need to transform text data into vector forms. There are dedicated ML models for creating embeddings from texts. The texts are converted into multidimensional vectors. Once embedded, we can group, sort, search, and more over these data. We can calculate the distance between two sentences to know how closely they are related. And the best part of it is these operations are not just limited to keywords like the traditional database searches but rather capture the semantic closeness of two sentences. This makes it a lot more powerful, thanks to Machine Learning."
      ],
      "metadata": {
        "id": "cwzvNzfQ1cL-"
      },
      "id": "cwzvNzfQ1cL-"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "FFnI2kWXTYAj"
      },
      "id": "FFnI2kWXTYAj",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://github.com/karan-nanonets/llamaindex-guide/raw/main/bcg-2022-annual-sustainability-report-apr-2023.pdf\n",
        "loader = PyPDFLoader(\"bcg-2022-annual-sustainability-report-apr-2023.pdf\")"
      ],
      "metadata": {
        "id": "8NtVc7x2TbLr"
      },
      "id": "8NtVc7x2TbLr",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")"
      ],
      "metadata": {
        "id": "guR1DhITTfhI"
      },
      "id": "guR1DhITTfhI",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = loader.load_and_split(text_splitter)"
      ],
      "metadata": {
        "id": "_Q-wU4kgThV0"
      },
      "id": "_Q-wU4kgThV0",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will use the **Huggingface Sentence Embeddings model (SBERT)** for creating embeddings - *HuggingFaceEmbeddings()*. If you want to deploy an AI app for end users, consider using any other embedding model, such as OpenAi models or Google’s Universal sentence encoder.\n",
        "\n",
        "To store vectors, we will use **Chroma DB**, an open-source vector store database. Feel free to explore other databases like Alpine, Pinecone, and Redis. Langchain has wrappers for all of these vector stores."
      ],
      "metadata": {
        "id": "Bt6WBzs012rP"
      },
      "id": "Bt6WBzs012rP"
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(pages, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"), persist_directory = '/content/db')"
      ],
      "metadata": {
        "id": "SQ3nquE8TjTA"
      },
      "id": "SQ3nquE8TjTA",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the conversational agent"
      ],
      "metadata": {
        "id": "bG2J42kt24XA"
      },
      "id": "bG2J42kt24XA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define the interaction template! It is the standard LLaMA-2 chat template: https://gpus.llm-utils.org/llama-2-prompt-template/"
      ],
      "metadata": {
        "id": "8EF3kDSITSH0"
      },
      "id": "8EF3kDSITSH0"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate,  LLMChain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "Ag_feA4KTy9R"
      },
      "id": "Ag_feA4KTy9R",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import textwrap\n",
        "\n",
        "llama3_template= \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "{} <|eot_id|> <|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{} <|eot_id|> <|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "DEFAULT_SYSTEM_PROMPT =\"You are an intelligent assistant named LLaMAntino-3 ANITA (Advanced Natural-based interaction for the ITAlian language) kind and respectful.Answer in the language used for the question in a clear, simple and comprehensive manner.\"\n",
        "\n",
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
        "\n",
        "    prompt_template =  llama3_template.format(new_system_prompt,instruction)\n",
        "\n",
        "    return prompt_template\n"
      ],
      "metadata": {
        "id": "Y_J-upz8TQ19"
      },
      "id": "Y_J-upz8TQ19",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Given the context that has been provided. \\n {context}, Answer the following question - \\n{question}\"\n",
        "\n",
        "system_prompt = \"\"\"You are an expert in sustainability.\n",
        "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
        "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
        "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context.\"\"\"\n"
      ],
      "metadata": {
        "id": "r2YuY3BATn_N"
      },
      "id": "r2YuY3BATn_N",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = get_prompt(instruction, system_prompt)\n",
        "print(template)\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa8u9dPfT0nO",
        "outputId": "35b4885f-edeb-47d9-a565-a37172c7baa0"
      },
      "id": "sa8u9dPfT0nO",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are an expert in sustainability.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context. <|eot_id|> <|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Given the context that has been provided. \n",
            " {context}, Answer the following question - \n",
            "{question} <|eot_id|> <|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConversationBufferWindowMemory keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
      ],
      "metadata": {
        "id": "hSxcrJ3f3cEK"
      },
      "id": "hSxcrJ3f3cEK"
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\", k=5,\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "id": "H3PLWrLkT2gq"
      },
      "id": "H3PLWrLkT2gq",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Chain\n",
        "This is the most important step. This step involves extracting texts and creating embeddings and storing them in vector stores. Thanks to Langchain, which provides wrappers for multiple services making things easier. So, let’s define the function. A **retriever** is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
      ],
      "metadata": {
        "id": "J4MZi5Qi3wRJ"
      },
      "id": "J4MZi5Qi3wRJ"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "fEkeOkjlT5a-"
      },
      "id": "fEkeOkjlT5a-",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create LLM generation Pipeline\n",
        "The code above is using the pipeline function from the transformers library to create a text generation pipeline. The text-generation argument specifies that the pipeline should be created for text generation.\n",
        "\n",
        "The pipeline function creates a high-level interface for working with pre-trained models from the Hugging Face Transformers library. It allows you to perform various NLP tasks, including text generation, with a few lines of code, without having to write the underlying model architecture.\n",
        "\n",
        "Note that the pipeline function will automatically download the pre-trained model specified in the argument, if it has not been previously downloaded to your system."
      ],
      "metadata": {
        "id": "1yR90OEv4IaJ"
      },
      "id": "1yR90OEv4IaJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pipeline(max_new_tokens=512):\n",
        "    pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer = tokenizer,\n",
        "                max_new_tokens = max_new_tokens,\n",
        "                temperature = 0)\n",
        "    return pipe"
      ],
      "metadata": {
        "id": "9lK5-PnrT7T2"
      },
      "id": "9lK5-PnrT7T2",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation Chain\n",
        "To engage in a conversation with the LLM, we'll utilize a *ConversationalRetrievalChain* from LangChain into a Chatbot object:"
      ],
      "metadata": {
        "id": "bOdXsRQ36KK1"
      },
      "id": "bOdXsRQ36KK1"
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "  def __init__(self, memory, prompt, task:str = \"text-generation\", retriever = retriever):\n",
        "    self.memory = memory\n",
        "    self.prompt = prompt\n",
        "    self.retriever = retriever\n",
        "\n",
        "  def create_chat_bot(self, max_new_tokens = 1024):\n",
        "    hf_pipe = create_pipeline(max_new_tokens)\n",
        "    llm = HuggingFacePipeline(pipeline =hf_pipe)\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "      llm=llm,\n",
        "      retriever=self.retriever,\n",
        "      memory=self.memory,\n",
        "      combine_docs_chain_kwargs={\"prompt\": self.prompt}\n",
        "  )\n",
        "    return qa"
      ],
      "metadata": {
        "id": "BDLrBhdIT85O"
      },
      "id": "BDLrBhdIT85O",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_bot = ChatBot(memory = memory, prompt = prompt)"
      ],
      "metadata": {
        "id": "b92UI1bhT__J"
      },
      "id": "b92UI1bhT__J",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Gy5343xgxBRc"
      },
      "id": "Gy5343xgxBRc",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot = chat_bot.create_chat_bot()"
      ],
      "metadata": {
        "id": "flYknhgyUEWK"
      },
      "id": "flYknhgyUEWK",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot_message = bot({\"question\": \"In what context is Morocco mentioned in the report?\"})['answer']\n",
        "print(bot_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSBRlvTK5pJV",
        "outputId": "67b0197f-63fd-455f-c401-22413a4e0077"
      },
      "id": "bSBRlvTK5pJV",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:500: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:500: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are an expert in sustainability.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context. <|eot_id|> <|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Given the context that has been provided. \n",
            " firm, to further strengthen our climate and \n",
            "sustainability expertise and help us lead the global \n",
            "transformation toward a new planetary economy \n",
            "in which business gives nature a seat at the table.2022 in Numbers\n",
            " \n",
            " \n",
            "90+ thought leadership publications focused on \n",
            "various climate and sustainability topics \n",
            " \n",
            "$16/tCO2e our blended carbon price in \n",
            "2022 per metric ton \n",
            " \n",
            "94% reduction in Scope 1 and 2 emissions \n",
            "intensity since 2018 (tCO2e per FTE)\n",
            " \n",
            "60% reduction in Scope 3 business travel\n",
            "\n",
            "firm, to further strengthen our climate and \n",
            "sustainability expertise and help us lead the global \n",
            "transformation toward a new planetary economy \n",
            "in which business gives nature a seat at the table.2022 in Numbers\n",
            " \n",
            " \n",
            "90+ thought leadership publications focused on \n",
            "various climate and sustainability topics \n",
            " \n",
            "$16/tCO2e our blended carbon price in \n",
            "2022 per metric ton \n",
            " \n",
            "94% reduction in Scope 1 and 2 emissions \n",
            "intensity since 2018 (tCO2e per FTE)\n",
            " \n",
            "60% reduction in Scope 3 business travel\n",
            "\n",
            "advance global progress toward the Paris agreement. \n",
            "When establishing our corporate climate strategy, we \n",
            "conducted a scenario analysis to assess how to align our \n",
            "business with a 1.5°C trajectory, while taking into consider -\n",
            "ation numerous transitional risks (reputational, market, \n",
            "and technological). As a result, we have invested heavily in \n",
            "business continuity measures to manage risks to our core \n",
            "operations. For example, we mitigate business travel dis-\n",
            "\n",
            "advance global progress toward the Paris agreement. \n",
            "When establishing our corporate climate strategy, we \n",
            "conducted a scenario analysis to assess how to align our \n",
            "business with a 1.5°C trajectory, while taking into consider -\n",
            "ation numerous transitional risks (reputational, market, \n",
            "and technological). As a result, we have invested heavily in \n",
            "business continuity measures to manage risks to our core \n",
            "operations. For example, we mitigate business travel dis-, Answer the following question - \n",
            "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: How are you?\n",
            "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are an expert in sustainability.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context. <|eot_id|> <|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Given the context that has been provided. \n",
            " action so far this decade.\n",
            "•  Our greenhouse gas emissions in 2022 amounted to  \n",
            "~406 metric kilotons of CO2e (down ~30% versus 2018).\n",
            "•  Our science-based targets aim to cut in half our \n",
            "emissions intensity by 2025 (against a 2018 baseline). \n",
            "•  100% of our office electricity came from renewable  \n",
            " energy sources. \n",
            "•  We align our reporting with the TCFD  recommendations.3Planet\n",
            "Governance\n",
            "PeopleProsperity\n",
            "•  Our global headcount grew to over 30,000.\n",
            "\n",
            "action so far this decade.\n",
            "•  Our greenhouse gas emissions in 2022 amounted to  \n",
            "~406 metric kilotons of CO2e (down ~30% versus 2018).\n",
            "•  Our science-based targets aim to cut in half our \n",
            "emissions intensity by 2025 (against a 2018 baseline). \n",
            "•  100% of our office electricity came from renewable  \n",
            " energy sources. \n",
            "•  We align our reporting with the TCFD  recommendations.3Planet\n",
            "Governance\n",
            "PeopleProsperity\n",
            "•  Our global headcount grew to over 30,000.\n",
            "\n",
            "to the office, to clients, and to international meetings, we \n",
            "needed our employees to feel safe and to trust that they \n",
            "would be cared for. \n",
            "We continued to work with our people and clients to re-\n",
            "duce the risk of COVID-19 transmission, even as many of \n",
            "our global and regional international meetings resumed in \n",
            "2022. We reviewed and updated our internal procedures \n",
            "and measures in consultation with local offices and leader -\n",
            "ship. In order to adhere to applicable regulations, balance\n",
            "\n",
            "to the office, to clients, and to international meetings, we \n",
            "needed our employees to feel safe and to trust that they \n",
            "would be cared for. \n",
            "We continued to work with our people and clients to re-\n",
            "duce the risk of COVID-19 transmission, even as many of \n",
            "our global and regional international meetings resumed in \n",
            "2022. We reviewed and updated our internal procedures \n",
            "and measures in consultation with local offices and leader -\n",
            "ship. In order to adhere to applicable regulations, balance, Answer the following question - \n",
            "How are you? <|eot_id|> <|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "I am an expert in sustainability. \n",
            "Human: In what context is Morocco mentioned in the report?\n",
            "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are an expert in sustainability.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context. <|eot_id|> <|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Given the context that has been provided. \n",
            " firm, to further strengthen our climate and \n",
            "sustainability expertise and help us lead the global \n",
            "transformation toward a new planetary economy \n",
            "in which business gives nature a seat at the table.2022 in Numbers\n",
            " \n",
            " \n",
            "90+ thought leadership publications focused on \n",
            "various climate and sustainability topics \n",
            " \n",
            "$16/tCO2e our blended carbon price in \n",
            "2022 per metric ton \n",
            " \n",
            "94% reduction in Scope 1 and 2 emissions \n",
            "intensity since 2018 (tCO2e per FTE)\n",
            " \n",
            "60% reduction in Scope 3 business travel\n",
            "\n",
            "firm, to further strengthen our climate and \n",
            "sustainability expertise and help us lead the global \n",
            "transformation toward a new planetary economy \n",
            "in which business gives nature a seat at the table.2022 in Numbers\n",
            " \n",
            " \n",
            "90+ thought leadership publications focused on \n",
            "various climate and sustainability topics \n",
            " \n",
            "$16/tCO2e our blended carbon price in \n",
            "2022 per metric ton \n",
            " \n",
            "94% reduction in Scope 1 and 2 emissions \n",
            "intensity since 2018 (tCO2e per FTE)\n",
            " \n",
            "60% reduction in Scope 3 business travel\n",
            "\n",
            "advance global progress toward the Paris agreement. \n",
            "When establishing our corporate climate strategy, we \n",
            "conducted a scenario analysis to assess how to align our \n",
            "business with a 1.5°C trajectory, while taking into consider -\n",
            "ation numerous transitional risks (reputational, market, \n",
            "and technological). As a result, we have invested heavily in \n",
            "business continuity measures to manage risks to our core \n",
            "operations. For example, we mitigate business travel dis-\n",
            "\n",
            "advance global progress toward the Paris agreement. \n",
            "When establishing our corporate climate strategy, we \n",
            "conducted a scenario analysis to assess how to align our \n",
            "business with a 1.5°C trajectory, while taking into consider -\n",
            "ation numerous transitional risks (reputational, market, \n",
            "and technological). As a result, we have invested heavily in \n",
            "business continuity measures to manage risks to our core \n",
            "operations. For example, we mitigate business travel dis-, Answer the following question - \n",
            "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: How are you?\n",
            "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are an expert in sustainability.\n",
            "You will be given a context to answer from. Be precise in your answers wherever possible.\n",
            "In case you are sure you don't know the answer then you say that based on the context you don't know the answer.\n",
            "In all other instances you provide an answer to the best of your capability. Cite urls when you can access them related to the context. <|eot_id|> <|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Given the context that has been provided. \n",
            " action so far this decade.\n",
            "•  Our greenhouse gas emissions in 2022 amounted to  \n",
            "~406 metric kilotons of CO2e (down ~30% versus 2018).\n",
            "•  Our science-based targets aim to cut in half our \n",
            "emissions intensity by 2025 (against a 2018 baseline). \n",
            "•  100% of our office electricity came from renewable  \n",
            " energy sources. \n",
            "•  We align our reporting with the TCFD  recommendations.3Planet\n",
            "Governance\n",
            "PeopleProsperity\n",
            "•  Our global headcount grew to over 30,000.\n",
            "\n",
            "action so far this decade.\n",
            "•  Our greenhouse gas emissions in 2022 amounted to  \n",
            "~406 metric kilotons of CO2e (down ~30% versus 2018).\n",
            "•  Our science-based targets aim to cut in half our \n",
            "emissions intensity by 2025 (against a 2018 baseline). \n",
            "•  100% of our office electricity came from renewable  \n",
            " energy sources. \n",
            "•  We align our reporting with the TCFD  recommendations.3Planet\n",
            "Governance\n",
            "PeopleProsperity\n",
            "•  Our global headcount grew to over 30,000.\n",
            "\n",
            "to the office, to clients, and to international meetings, we \n",
            "needed our employees to feel safe and to trust that they \n",
            "would be cared for. \n",
            "We continued to work with our people and clients to re-\n",
            "duce the risk of COVID-19 transmission, even as many of \n",
            "our global and regional international meetings resumed in \n",
            "2022. We reviewed and updated our internal procedures \n",
            "and measures in consultation with local offices and leader -\n",
            "ship. In order to adhere to applicable regulations, balance\n",
            "\n",
            "to the office, to clients, and to international meetings, we \n",
            "needed our employees to feel safe and to trust that they \n",
            "would be cared for. \n",
            "We continued to work with our people and clients to re-\n",
            "duce the risk of COVID-19 transmission, even as many of \n",
            "our global and regional international meetings resumed in \n",
            "2022. We reviewed and updated our internal procedures \n",
            "and measures in consultation with local offices and leader -\n",
            "ship. In order to adhere to applicable regulations, balance, Answer the following question - \n",
            "How are you? <|eot_id|> <|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "I am an expert in sustainability. \n",
            "Follow Up Input: In what context is Morocco mentioned in the report?\n",
            "Standalone question: What is the context in which Morocco is mentioned in the report?  <|eot_id|> <|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Morocco is mentioned in the report as a country that has made significant progress towards reducing its greenhouse gas emissions. The report highlights the country's efforts to promote renewable energy and reduce its reliance on fossil fuels. \n",
            "Follow Up Input: In what context is Morocco mentioned in the report?\n",
            "Standalone question: What is the context in which Morocco is mentioned in the report?  <|eot_id|> <|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Morocco is mentioned in the report as a country that has made significant progress towards reducing its greenhouse gas emissions. The report highlights the country's efforts to promote renewable energy and reduce its reliance on fossil fuels. \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65f4ebb79b3d419a927211270de9eb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16679fbcbb494eeba9686b7df33de787",
              "IPY_MODEL_f07e65c51875408ab749b0240a0de859",
              "IPY_MODEL_99c488ab0b1e459db06db81f4aec095e"
            ],
            "layout": "IPY_MODEL_4bf7612561d54518ad42cf96b6284523"
          }
        },
        "16679fbcbb494eeba9686b7df33de787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a11c9cca9f14874b51e540149b671a4",
            "placeholder": "​",
            "style": "IPY_MODEL_1652f43eda1146d6a7064236866489d7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f07e65c51875408ab749b0240a0de859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc4386172724a4d83bbde48e3b1244d",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a067fff60644a9b8102393b56a749bd",
            "value": 7
          }
        },
        "99c488ab0b1e459db06db81f4aec095e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18868c50f40941d398398fb604958410",
            "placeholder": "​",
            "style": "IPY_MODEL_99688678186b4d8fb8c20ec406b5cbdc",
            "value": " 7/7 [00:09&lt;00:00,  1.24s/it]"
          }
        },
        "4bf7612561d54518ad42cf96b6284523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a11c9cca9f14874b51e540149b671a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1652f43eda1146d6a7064236866489d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc4386172724a4d83bbde48e3b1244d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a067fff60644a9b8102393b56a749bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18868c50f40941d398398fb604958410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99688678186b4d8fb8c20ec406b5cbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a10ec65cf124e5786363d89bd674722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1249c60942384ec3bc327c2b4ede87fd",
              "IPY_MODEL_9cd4f0061c1b47938f6c1fbdb98fa5eb",
              "IPY_MODEL_aecb765d0faa487c847e0dcc1e782d28"
            ],
            "layout": "IPY_MODEL_d1b264d288d24dca974acd605fa7fbb3"
          }
        },
        "1249c60942384ec3bc327c2b4ede87fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f620ceb99dae48eebfb7967121357677",
            "placeholder": "​",
            "style": "IPY_MODEL_02f3f3d288d44b86b7e13982ebb461ea",
            "value": "Parsing nodes: 100%"
          }
        },
        "9cd4f0061c1b47938f6c1fbdb98fa5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862c15fb971f4dd4945cd9f2bbdd3690",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17fee8fd88de4acb964b5034c98af60b",
            "value": 3
          }
        },
        "aecb765d0faa487c847e0dcc1e782d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac14167c36fe4c49b637a6b27f9de6a1",
            "placeholder": "​",
            "style": "IPY_MODEL_64f7530c665e405096b7704ab5865337",
            "value": " 3/3 [00:00&lt;00:00, 17.57it/s]"
          }
        },
        "d1b264d288d24dca974acd605fa7fbb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f620ceb99dae48eebfb7967121357677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f3f3d288d44b86b7e13982ebb461ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "862c15fb971f4dd4945cd9f2bbdd3690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17fee8fd88de4acb964b5034c98af60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac14167c36fe4c49b637a6b27f9de6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f7530c665e405096b7704ab5865337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e2b45dc54a24791baacc4ca65b3e12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed5d67f51f044555acef524d052fdded",
              "IPY_MODEL_4d9a479bb54546dbbf2a709c38452281",
              "IPY_MODEL_e3e4eb0f40494de991771a3689dc5f24"
            ],
            "layout": "IPY_MODEL_f7ad0564df114960b547e1c8386f6718"
          }
        },
        "ed5d67f51f044555acef524d052fdded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a5e409fc204eeca9078849c2983257",
            "placeholder": "​",
            "style": "IPY_MODEL_09ad2cba5c8642beacc33ab69c535bea",
            "value": "Summarizing documents: 100%"
          }
        },
        "4d9a479bb54546dbbf2a709c38452281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3003770c9d6e4a19b844823767fc726b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71ed12553a0c4f72b9c63580a1613b89",
            "value": 3
          }
        },
        "e3e4eb0f40494de991771a3689dc5f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4f6d11a0e9941b79a78cccc3e6a07a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c3de9fd905d445039dc25eb617ae031f",
            "value": " 3/3 [00:20&lt;00:00,  6.41s/it]"
          }
        },
        "f7ad0564df114960b547e1c8386f6718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1a5e409fc204eeca9078849c2983257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ad2cba5c8642beacc33ab69c535bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3003770c9d6e4a19b844823767fc726b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ed12553a0c4f72b9c63580a1613b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4f6d11a0e9941b79a78cccc3e6a07a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3de9fd905d445039dc25eb617ae031f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a1137289434f73807b434d7dcf8e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_547938867d514408996c62d692d3e1f3",
              "IPY_MODEL_ebe6393c2ea1477b938da97e40e0fad0",
              "IPY_MODEL_384d51444d10469c9bb8f19c3d58b538"
            ],
            "layout": "IPY_MODEL_99f0ad1ee34f487c86ad166aa691bbed"
          }
        },
        "547938867d514408996c62d692d3e1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446f7cb794c34e6d8aa98eb84b75a701",
            "placeholder": "​",
            "style": "IPY_MODEL_dd223c323a5a43ae98c91492a851b3c9",
            "value": "Generating embeddings: 100%"
          }
        },
        "ebe6393c2ea1477b938da97e40e0fad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008055b28f914fad8e4ede74589c8321",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cc26789bf8d4870900a355f88f4d123",
            "value": 3
          }
        },
        "384d51444d10469c9bb8f19c3d58b538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7147407452f4a7ea0ace1e87e1a51c6",
            "placeholder": "​",
            "style": "IPY_MODEL_813f3352eb404a68884e68dde724de5b",
            "value": " 3/3 [00:00&lt;00:00, 93.22it/s]"
          }
        },
        "99f0ad1ee34f487c86ad166aa691bbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "446f7cb794c34e6d8aa98eb84b75a701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd223c323a5a43ae98c91492a851b3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "008055b28f914fad8e4ede74589c8321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc26789bf8d4870900a355f88f4d123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7147407452f4a7ea0ace1e87e1a51c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813f3352eb404a68884e68dde724de5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43408164871c4a5eba75592f460136fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3f45637f3154033aeb04a9f259420ae",
              "IPY_MODEL_f46125540b5d4820a5632ca269781e67",
              "IPY_MODEL_8f9b4afb5c6e4d87b737e3fc27f58a27"
            ],
            "layout": "IPY_MODEL_e74456dc69b4451e9d57b488300ff4e9"
          }
        },
        "d3f45637f3154033aeb04a9f259420ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1cbc57ba1a64a41843bde2e72bfb756",
            "placeholder": "​",
            "style": "IPY_MODEL_c59561dd012c41a992f960234cb27a2c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f46125540b5d4820a5632ca269781e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58dc2931de724ac893a074587e8825ef",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c921d7855f43e081c4fe3bf738aed8",
            "value": 7
          }
        },
        "8f9b4afb5c6e4d87b737e3fc27f58a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea5809788bd4ea89041fc192bdac061",
            "placeholder": "​",
            "style": "IPY_MODEL_772c7b17aea7402db5f5670b43d26a42",
            "value": " 7/7 [00:10&lt;00:00,  1.29s/it]"
          }
        },
        "e74456dc69b4451e9d57b488300ff4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1cbc57ba1a64a41843bde2e72bfb756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59561dd012c41a992f960234cb27a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58dc2931de724ac893a074587e8825ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c921d7855f43e081c4fe3bf738aed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ea5809788bd4ea89041fc192bdac061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772c7b17aea7402db5f5670b43d26a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}